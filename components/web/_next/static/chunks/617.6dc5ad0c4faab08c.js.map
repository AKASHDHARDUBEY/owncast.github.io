{"version":3,"file":"static/chunks/617.6dc5ad0c4faab08c.js","mappings":"kGAAA,SAAAA,EAAAC,CAAA,EAEA,QADAC,EAAA,GAAcC,EAAAF,EAAAG,KAAA,MACdC,EAAA,EAAkBA,EAAAF,EAAAG,MAAA,CAAkB,EAAAD,EAAAH,CAAA,CAAAC,CAAA,CAAAE,EAAA,KACpC,OAAAH,CACA,+CAEA,IAAAK,EAAAP,EAAA,mEAEAQ,EAAAR,EAAA,2JAEAS,EAAAT,EAAA,oOACAU,EAAA,oBAEA,SAAAC,EAAAC,CAAA,CAAAC,CAAA,CAAAC,CAAA,EAEA,OADAD,EAAAE,QAAA,CAAAD,EACAA,EAAAF,EAAAC,EACA,CACA,SAAAG,EAAAJ,CAAA,CAAAC,CAAA,EACA,IAAAI,EAAAJ,EAAAI,YAAA,CACAJ,EAAAI,YAAA,IACA,IAAAC,EAAAN,EAAAO,IAAA,GAEA,QAAAD,GAAA,CAAAL,EAAAO,QAAA,EAAAP,EAAAQ,QAAA,CAEA,OADAR,EAAAS,mBAAA,IACAX,EAAAC,EAAAC,EAAAU,EAAAL,GAwFA,CArFA,GAAAA,KAAAA,EAAA,CAEA,GADAL,EAAAS,mBAAA,IACAT,EAAAO,QAAA,CAEA,OADAP,EAAAO,QAAA,IACA,QAGA,CADA,GAAAP,EAAAQ,QAAA,CACA,OAAAV,EAAAC,EAAAC,EAAAU,EAAAL,GAAA,KAsDA,CAnDA,sBAAyBM,IAAA,CAAAN,GAOzB,MANAA,KAAAA,GAAAD,EACAJ,EAAAQ,QAAA,IACA,KAAAH,IACAL,EAAAQ,QAAA,IACAR,EAAAS,mBAAA,KAEA,KAGA,QAAAE,IAAA,CAAAN,GAGA,OAFAL,EAAAS,mBAAA,IACAV,EAAAa,QAAA,WACA,QA8DA,CA3DA,GAAAP,KAAAA,GAAAN,EAAAc,GAAA,MAEA,OADAb,EAAAS,mBAAA,IACAX,EAAAC,EAAAC,EAAAc,EAyDA,CAtDA,GAAAT,KAAAA,GAAAN,EAAAgB,KAAA,aAEA,OADAf,EAAAS,mBAAA,IACAX,EAAAC,EAAAC,EAAAgB,EAoDA,CAjDA,GAAAX,KAAAA,GAAAN,EAAAc,GAAA,MAGA,OAFAb,EAAAS,mBAAA,IACAV,EAAAkB,SAAA,GACA,SA8CA,CA3CA,GAAAZ,KAAAA,QAIA,CAHAN,EAAAc,GAAA,MACAd,EAAAa,QAAA,mBAEAhB,GAAAA,EAAAsB,oBAAA,CAAAnB,EAAAoB,OAAA,KACA,WAGAnB,EAAAS,mBAAA,IACAT,EAAAI,YAAA,IACA,UACA,CAGA,GAAAP,EAAAc,IAAA,CAAAN,GAGA,OAFAL,EAAAS,mBAAA,IACAV,EAAAa,QAAA,CAAAf,GACA,UA0BA,CAtBAE,EAAAa,QAAA,eACA,IAAAQ,EAAArB,EAAAoB,OAAA,UAEA,GAAAzB,EAAAwB,oBAAA,CAAAE,GACA,UAEAzB,GAAAA,EAAAuB,oBAAA,CAAAE,IACA,EAAAD,OAAA,GAAAJ,KAAA,wBAAAhB,KAAAA,EAAAsB,IAAA,IACA,CAAA1B,CAAAA,GAAAA,EAAAuB,oBAAA,CAAAE,EAAAE,WAAA,MACAtB,EAAAI,YAAA,IACAJ,EAAAS,mBAAA,IACA,WAEAT,EAAAO,QAAA,EACAP,EAAAS,mBAAA,IACA,UAEAV,EAAAwB,GAAA,CAAAH,EAAA3B,MAAA,EAAAM,KAAAA,EAAAyB,MAAA,CAAAC,MAAA,CAAA1B,EAAAwB,GAAA,CAAAH,EAAA3B,MAAA,KAAAO,EAAAS,mBAAA,CACA,WAEAT,EAAAS,mBAAA,IACA,KAjBA,CAkBA,CAGA,SAAAC,EAAAgB,CAAA,EACA,gBAAA3B,CAAA,CAAAC,CAAA,EAEA,IADA,IAAAM,EAAAqB,EAAA,GAAAC,EAAA,GACA,MAAAtB,CAAAA,EAAAP,EAAAO,IAAA,MACA,MAAAoB,GAAA,CAAAC,EAAA,CACAC,EAAA,GACA,MACA,GACAF,KAAAA,GAAA3B,KAAAA,EAAAsB,IAAA,KAAAM,EAAA,CACA3B,EAAAO,QAAA,IACAqB,EAAA,GACA,MACA,EACA,CAAAD,GAAArB,MAAAA,CACA,CAEA,OADAsB,GAAA5B,CAAAA,EAAAE,QAAA,CAAAC,CAAA,EACA,QACA,CACA,CAEA,SAAAW,EAAAf,CAAA,CAAAC,CAAA,EAEA,IADA,IAAAK,EAAAwB,EAAA,GACAxB,EAAAN,EAAAO,IAAA,KACA,GAAAD,KAAAA,GAAAwB,EAAA,CACA7B,EAAAE,QAAA,CAAAC,EACA,MACA,EACAE,KAAAA,CACA,CACA,eACA,CAEA,SAAAW,EAAAjB,CAAA,CAAAC,CAAA,EAEA,IADA,IAAAK,EAAAwB,EAAA,EACAxB,EAAAN,EAAAO,IAAA,KACA,GAAAD,KAAAA,GAAAwB,GAAAA,EAAA,CACA7B,EAAAE,QAAA,CAAAC,EACA,MACA,KACAE,EACAwB,IACA,KAAAxB,GACAwB,CAAAA,EAAA,EACA,CACA,YACA,CAGO,IAAAC,EAAA,CACPC,KAAA,WAEAC,WAAA,WACA,OACA9B,SAAAC,EACAC,aAAA,GACAI,SAAA,GACAD,SAAA,GACAE,oBAAA,EACA,CACA,EAEAwB,MAAA,SAAAlC,CAAA,CAAAC,CAAA,SACA,EAAAkC,QAAA,QACAlC,EAAAE,QAAA,CAAAH,EAAAC,EADA,EAGAmC,aAAA,CACAC,cAAA,CAAoBC,KAAA,KAAAC,MAAA,CAAoBC,KAAA,KAAAC,MAAA,MACxC,CACA","sources":["webpack://_N_E/./node_modules/@codemirror/legacy-modes/mode/velocity.js","webpack://_N_E/<anon>"],"sourcesContent":["function parseWords(str) {\n  var obj = {}, words = str.split(\" \");\n  for (var i = 0; i < words.length; ++i) obj[words[i]] = true;\n  return obj;\n}\n\nvar keywords = parseWords(\"#end #else #break #stop #[[ #]] \" +\n                          \"#{end} #{else} #{break} #{stop}\");\nvar functions = parseWords(\"#if #elseif #foreach #set #include #parse #macro #define #evaluate \" +\n                           \"#{if} #{elseif} #{foreach} #{set} #{include} #{parse} #{macro} #{define} #{evaluate}\");\nvar specials = parseWords(\"$foreach.count $foreach.hasNext $foreach.first $foreach.last $foreach.topmost $foreach.parent.count $foreach.parent.hasNext $foreach.parent.first $foreach.parent.last $foreach.parent $velocityCount $!bodyContent $bodyContent\");\nvar isOperatorChar = /[+\\-*&%=<>!?:\\/|]/;\n\nfunction chain(stream, state, f) {\n  state.tokenize = f;\n  return f(stream, state);\n}\nfunction tokenBase(stream, state) {\n  var beforeParams = state.beforeParams;\n  state.beforeParams = false;\n  var ch = stream.next();\n  // start of unparsed string?\n  if ((ch == \"'\") && !state.inString && state.inParams) {\n    state.lastTokenWasBuiltin = false;\n    return chain(stream, state, tokenString(ch));\n  }\n  // start of parsed string?\n  else if ((ch == '\"')) {\n    state.lastTokenWasBuiltin = false;\n    if (state.inString) {\n      state.inString = false;\n      return \"string\";\n    }\n    else if (state.inParams)\n      return chain(stream, state, tokenString(ch));\n  }\n  // is it one of the special signs []{}().,;? Separator?\n  else if (/[\\[\\]{}\\(\\),;\\.]/.test(ch)) {\n    if (ch == \"(\" && beforeParams)\n      state.inParams = true;\n    else if (ch == \")\") {\n      state.inParams = false;\n      state.lastTokenWasBuiltin = true;\n    }\n    return null;\n  }\n  // start of a number value?\n  else if (/\\d/.test(ch)) {\n    state.lastTokenWasBuiltin = false;\n    stream.eatWhile(/[\\w\\.]/);\n    return \"number\";\n  }\n  // multi line comment?\n  else if (ch == \"#\" && stream.eat(\"*\")) {\n    state.lastTokenWasBuiltin = false;\n    return chain(stream, state, tokenComment);\n  }\n  // unparsed content?\n  else if (ch == \"#\" && stream.match(/ *\\[ *\\[/)) {\n    state.lastTokenWasBuiltin = false;\n    return chain(stream, state, tokenUnparsed);\n  }\n  // single line comment?\n  else if (ch == \"#\" && stream.eat(\"#\")) {\n    state.lastTokenWasBuiltin = false;\n    stream.skipToEnd();\n    return \"comment\";\n  }\n  // variable?\n  else if (ch == \"$\") {\n    stream.eat(\"!\");\n    stream.eatWhile(/[\\w\\d\\$_\\.{}-]/);\n    // is it one of the specials?\n    if (specials && specials.propertyIsEnumerable(stream.current())) {\n      return \"keyword\";\n    }\n    else {\n      state.lastTokenWasBuiltin = true;\n      state.beforeParams = true;\n      return \"builtin\";\n    }\n  }\n  // is it a operator?\n  else if (isOperatorChar.test(ch)) {\n    state.lastTokenWasBuiltin = false;\n    stream.eatWhile(isOperatorChar);\n    return \"operator\";\n  }\n  else {\n    // get the whole word\n    stream.eatWhile(/[\\w\\$_{}@]/);\n    var word = stream.current();\n    // is it one of the listed keywords?\n    if (keywords && keywords.propertyIsEnumerable(word))\n      return \"keyword\";\n    // is it one of the listed functions?\n    if (functions && functions.propertyIsEnumerable(word) ||\n        (stream.current().match(/^#@?[a-z0-9_]+ *$/i) && stream.peek()==\"(\") &&\n        !(functions && functions.propertyIsEnumerable(word.toLowerCase()))) {\n      state.beforeParams = true;\n      state.lastTokenWasBuiltin = false;\n      return \"keyword\";\n    }\n    if (state.inString) {\n      state.lastTokenWasBuiltin = false;\n      return \"string\";\n    }\n    if (stream.pos > word.length && stream.string.charAt(stream.pos-word.length-1)==\".\" && state.lastTokenWasBuiltin)\n      return \"builtin\";\n    // default: just a \"word\"\n    state.lastTokenWasBuiltin = false;\n    return null;\n  }\n}\n\nfunction tokenString(quote) {\n  return function(stream, state) {\n    var escaped = false, next, end = false;\n    while ((next = stream.next()) != null) {\n      if ((next == quote) && !escaped) {\n        end = true;\n        break;\n      }\n      if (quote=='\"' && stream.peek() == '$' && !escaped) {\n        state.inString = true;\n        end = true;\n        break;\n      }\n      escaped = !escaped && next == \"\\\\\";\n    }\n    if (end) state.tokenize = tokenBase;\n    return \"string\";\n  };\n}\n\nfunction tokenComment(stream, state) {\n  var maybeEnd = false, ch;\n  while (ch = stream.next()) {\n    if (ch == \"#\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = (ch == \"*\");\n  }\n  return \"comment\";\n}\n\nfunction tokenUnparsed(stream, state) {\n  var maybeEnd = 0, ch;\n  while (ch = stream.next()) {\n    if (ch == \"#\" && maybeEnd == 2) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    if (ch == \"]\")\n      maybeEnd++;\n    else if (ch != \" \")\n      maybeEnd = 0;\n  }\n  return \"meta\";\n}\n// Interface\n\nexport const velocity = {\n  name: \"velocity\",\n\n  startState: function() {\n    return {\n      tokenize: tokenBase,\n      beforeParams: false,\n      inParams: false,\n      inString: false,\n      lastTokenWasBuiltin: false\n    };\n  },\n\n  token: function(stream, state) {\n    if (stream.eatSpace()) return null;\n    return state.tokenize(stream, state);\n  },\n  languageData: {\n    commentTokens: {line: \"##\", block: {open: \"#*\", close: \"*#\"}}\n  }\n};\n"],"names":["parseWords","str","obj","words","split","i","length","keywords","functions","specials","isOperatorChar","chain","stream","state","f","tokenize","tokenBase","beforeParams","ch","next","inString","inParams","lastTokenWasBuiltin","tokenString","test","eatWhile","eat","tokenComment","match","tokenUnparsed","skipToEnd","propertyIsEnumerable","current","word","peek","toLowerCase","pos","string","charAt","quote","escaped","end","maybeEnd","velocity","name","startState","token","eatSpace","languageData","commentTokens","line","block","open","close"],"sourceRoot":""}