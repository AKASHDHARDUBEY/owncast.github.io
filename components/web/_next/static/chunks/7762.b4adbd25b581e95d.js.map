{"version":3,"file":"static/chunks/7762.b4adbd25b581e95d.js","mappings":"6IAAA,IAAAA,EAAA,4CACAC,EAAA,uBACAC,EAAA,qBAkDA,SAAAC,EAAAC,CAAA,CAAAC,CAAA,EACA,IApBAC,EAoBAA,EAAAF,EAAAG,IAAA,GAQA,MAPAD,KAAAA,EACAD,EAAAG,QAAA,CA9CA,SAAAJ,CAAA,CAAAC,CAAA,EAEA,IADA,IAAAE,EAAAE,EAAA,GAEA,IADA,EAAAF,CAAAA,EAAAH,EAAAG,IAAA,KACAA,CAAAA,GA2CAD,GA3CAG,CAAA,GACAA,EAAA,CAAAA,GAAAF,MAAAA,EAIA,OADAE,GAAAJ,CAAAA,EAAAG,QAAA,CAAAL,CAAA,EACA,QACA,EAsCAF,EAAAS,IAAA,CAAAJ,GACAD,EAAAG,QAAA,CAnCA,SAAAJ,CAAA,CAAAC,CAAA,EAOA,MANAM,KAkCAL,EAjCAF,EAAAQ,GAAA,OACA,KAgCAN,GA/BAF,EAAAQ,GAAA,OAEAP,EAAAG,QAAA,CAAAL,EACA,UACA,EA4BAH,EAAAU,IAAA,CAAAJ,IACAD,CAAAA,EAAAG,QAAA,EA1BAF,EA0BAA,EAzBA,SAAAF,CAAA,CAAAC,CAAA,EAEA,IADA,IA/BAQ,EA+BAA,EAAAP,EACA,CAAAA,EAAAF,EAAAU,IAAA,KAAAR,IAAA,EAAAA,EAAAS,KAAA,CAAAf,IACAa,GAAAT,EAAAG,IAAA,SAIA,CADAF,EAAAG,QAAA,CAAAL,EACAD,EAAAQ,IAAA,CAAAG,IACA,WArCAG,WADAH,EAuCAA,GAtCAI,QAAA,KAAAJ,EAuCA,SACAT,KAAAA,EAAAU,IAAA,GACA,eAEA,UAWA,EAEA,EAAAN,QAAA,EAAAL,EAAAE,EAAAG,QAAA,CAAAJ,EAAAC,GAAA,KAGO,IAAAa,EAAA,CACPC,KAAA,OAEAC,WAAA,WACA,OACAZ,SAAAL,CACA,CACA,EAEAkB,MAAA,SAAAjB,CAAA,CAAAC,CAAA,SACA,EAAAiB,QAAA,QACAjB,EAAAG,QAAA,CAAAJ,EAAAC,EADA,CAGA","sources":["webpack://_N_E/./node_modules/@codemirror/legacy-modes/mode/solr.js","webpack://_N_E/<anon>"],"sourcesContent":["var isStringChar = /[^\\s\\|\\!\\+\\-\\*\\?\\~\\^\\&\\:\\(\\)\\[\\]\\{\\}\\\"\\\\]/;\nvar isOperatorChar = /[\\|\\!\\+\\-\\*\\?\\~\\^\\&]/;\nvar isOperatorString = /^(OR|AND|NOT|TO)$/i;\n\nfunction isNumber(word) {\n  return parseFloat(word).toString() === word;\n}\n\nfunction tokenString(quote) {\n  return function(stream, state) {\n    var escaped = false, next;\n    while ((next = stream.next()) != null) {\n      if (next == quote && !escaped) break;\n      escaped = !escaped && next == \"\\\\\";\n    }\n\n    if (!escaped) state.tokenize = tokenBase;\n    return \"string\";\n  };\n}\n\nfunction tokenOperator(operator) {\n  return function(stream, state) {\n    if (operator == \"|\")\n      stream.eat(/\\|/);\n    else if (operator == \"&\")\n      stream.eat(/\\&/);\n\n    state.tokenize = tokenBase;\n    return \"operator\";\n  };\n}\n\nfunction tokenWord(ch) {\n  return function(stream, state) {\n    var word = ch;\n    while ((ch = stream.peek()) && ch.match(isStringChar) != null) {\n      word += stream.next();\n    }\n\n    state.tokenize = tokenBase;\n    if (isOperatorString.test(word))\n      return \"operator\";\n    else if (isNumber(word))\n      return \"number\";\n    else if (stream.peek() == \":\")\n      return \"propertyName\";\n    else\n      return \"string\";\n  };\n}\n\nfunction tokenBase(stream, state) {\n  var ch = stream.next();\n  if (ch == '\"')\n    state.tokenize = tokenString(ch);\n  else if (isOperatorChar.test(ch))\n    state.tokenize = tokenOperator(ch);\n  else if (isStringChar.test(ch))\n    state.tokenize = tokenWord(ch);\n\n  return (state.tokenize != tokenBase) ? state.tokenize(stream, state) : null;\n}\n\nexport const solr = {\n  name: \"solr\",\n\n  startState: function() {\n    return {\n      tokenize: tokenBase\n    };\n  },\n\n  token: function(stream, state) {\n    if (stream.eatSpace()) return null;\n    return state.tokenize(stream, state);\n  }\n};\n"],"names":["isStringChar","isOperatorChar","isOperatorString","tokenBase","stream","state","ch","next","tokenize","escaped","test","operator","eat","word","peek","match","parseFloat","toString","solr","name","startState","token","eatSpace"],"sourceRoot":""}