{"version":3,"file":"static/chunks/4511.1b7139b40c7d4995.js","mappings":"mJACA,IAAAA,EAAA,GAEAC,EAAA,CACA,+BACA,4BACA,4BACA,4BACA,0BACA,uBACA,8BACA,iBACA,EAEAC,EAAA,WACAC,EAAA,cACAC,EAAA,aACAC,EAAA,aACAC,EAAA,QAEAC,EAAA,eACAC,EAAA,eACAC,EAAA,kBACAC,EAAA,kBAEAC,EAAA,WACAC,EAAA,WAEAC,EAAA,YAEA,SAAAC,EAAAC,CAAA,CAAAC,CAAA,CAAAC,CAAA,EAEA,OADAD,EAAAE,QAAA,CAAAD,EACAA,EAAAF,EAAAC,EACA,CAEA,SAAAG,EAAAJ,CAAA,CAAAC,CAAA,EACA,IAAAI,EAAAL,EAAAK,GAAA,GAAAC,EAAAN,EAAAO,IAAA,GAKA,GAHAN,EAAAO,KAAA,IAGAH,GAAA,cAAsBI,IAAA,CAAAH,GAAA,CACtB,GAAAN,EAAAU,KAAA,CAAAd,GAEA,OADAK,EAAAO,KAAA,IACAT,EAAAC,EAAAC,EAAAU,EACA,CACA,GAAAX,EAAAU,KAAA,CAAAnB,GACA,cACA,GAAAS,EAAAU,KAAA,CAAArB,IAAAW,EAAAU,KAAA,CAAApB,IAEAU,EAAAU,KAAA,CAAAlB,IAAAQ,EAAAU,KAAA,CAAAjB,IAAAO,EAAAU,KAAA,CAAAhB,IAAAM,EAAAU,KAAA,CAAAf,GADA,gBAGA,GAAAK,EAAAU,KAAA,CAAAtB,GACA,yBACA,GAEAY,EAAAY,IAAA,GACAP,GAAA,eAAsBI,IAAA,CAAAH,GAAA,CACtB,GAAAA,KAAAA,EAEA,OADAN,EAAAa,SAAA,GACA,QACA,CACA,GAAAP,KAAAA,EAEA,OADAN,EAAAc,QAAA,MACA,SACA,CACA,GAAAR,KAAAA,EAEA,OADAN,EAAAc,QAAA,MACA,SACA,CACA,GAAAR,KAAAA,EAEA,OADAN,EAAAc,QAAA,MACA,SACA,CACA,GAAAR,KAAAA,EAEA,OADAN,EAAAc,QAAA,MACA,SACA,CACA,GAAAR,KAAAA,EAEA,OADAN,EAAAc,QAAA,MACA,OACA,CACA,GAAAR,KAAAA,EACA,eACA,GAEAA,KAAAA,GAAcN,EAAAU,KAAA,OACd,OAAAX,EAAAC,EAAAC,EAAAU,EAAA,CAGA,WAAAF,IAAA,CAAAH,IACA,QAAAG,IAAA,CAAAT,EAAAO,IAAA,KACAP,EAAAU,KAAA,4EACA,aAGA,GAAAJ,KAAAA,EACA,eAEA,QAAAA,GAGA,SAAAG,IAAA,CAAAH,IAAAN,EAAAU,KAAA,CAAAJ,GAFA,cAKA,GAAAA,KAAAA,EAEA,OADAN,EAAAc,QAAA,CAAA3B,GACA,MACA,CAEA,QAAAsB,IAAA,CAAAH,GAEA,OADAN,EAAAc,QAAA,OACA,QACA,CAEA,GAAAR,KAAAA,EAAA,CACA,GAAAN,EAAAe,GAAA,MACA,OAAAhB,EAAAC,EAAAC,EAAAe,EAGA,CAFM,GAAAhB,EAAAe,GAAA,MACN,OAAAhB,EAAAC,EAAAC,EAAAgB,EACA,CACA,GAEAX,KAAAA,GAAAN,EAAAe,GAAA,MACA,OAAAhB,EAAAC,EAAAC,EAAAiB,EAAA,CAGA,GAAAZ,KAAAA,GAAAN,EAAAe,GAAA,OAEA,GAAAf,KAAAA,EAAAO,IAAA,GACA,OAAAR,EAAAC,EAAAC,EAAAkB,EAAA,CAEA,GAAAnB,KAAAA,EAAAO,IAAA,GACA,cACA,MAEA,KAAAD,GAAAN,EAAAe,GAAA,MACAhB,EAAAC,EAAAC,EAAAmB,GAEAd,KAAAA,GAAAN,EAAAe,GAAA,MACAhB,EAAAC,EAAAC,EAAAoB,IAGArB,EAAAc,QAAA,YACA7B,EAAAqC,oBAAA,CAAAtB,EAAAuB,OAAA,mBAPA,CAWA,SAAAP,EAAAhB,CAAA,CAAAC,CAAA,EAEA,IADA,IAAAK,EAAAkB,EAAA,GACAlB,EAAAN,EAAAY,IAAA,KACA,GAAAN,KAAAA,GAAAkB,EAAA,CACAvB,EAAAE,QAAA,CAAAC,EACA,MACA,EACAE,KAAAA,CACA,CACA,eACA,CAGA,SAAAc,EAAApB,CAAA,CAAAC,CAAA,EAGA,IAFA,IACAK,EADAkB,EAAA,GAEAlB,EAAAN,EAAAY,IAAA,KACA,GAAAN,KAAAA,GAAAkB,EAAA,CACAvB,EAAAE,QAAA,CAAAC,EACA,MACA,EACAE,KAAAA,CACA,CACA,cACA,CAGA,SAAAK,EAAAX,CAAA,CAAAC,CAAA,EACA,IAAAwB,EAAAxB,EAAAO,KAAA,QAEA,GAAAR,EAAAuB,OAAA,GACA,UAGA,CAAAE,GAAAzB,EAAAU,KAAA,CAAAZ,IAKA2B,GAAAzB,EAAAK,GAAA,IAAAL,EAAAU,KAAA,CAAAb,IAJAI,EAAAE,QAAA,CAAAC,EACA,YAQAJ,EAAAY,IAAA,GACA,UAbA,CAiBA,SAAAK,EAAAjB,CAAA,CAAAC,CAAA,EAGA,IAFA,IACAK,EADAkB,EAAA,GAEAlB,EAAAN,EAAAY,IAAA,KACA,GAAAN,KAAAA,GAAAkB,EAAA,CACAvB,EAAAE,QAAA,CAAAC,EACA,MACA,EACAE,KAAAA,CACA,CACA,gBACA,CAGA,SAAAY,EAAAlB,CAAA,CAAAC,CAAA,EAGA,IAFA,IACAK,EADAkB,EAAA,GAEAlB,EAAAN,EAAAY,IAAA,KACA,GAAAN,KAAAA,GAAAkB,EAAA,CACAvB,EAAAE,QAAA,CAAAC,EACA,MACA,EACAE,KAAAA,CACA,CACA,YACA,CAIA,SAAAa,EAAAnB,CAAA,CAAAC,CAAA,EAGA,IAFA,IAAAK,EAAAkB,EAAA,GAEAlB,EAAAN,EAAAY,IAAA,KACA,GAAAN,KAAAA,GAAAkB,EAAA,CACAvB,EAAAE,QAAA,CAAAC,EACA,MACA,EACAE,KAAAA,CACA,CACA,eACA,CAGA,SAAAe,EAAArB,CAAA,CAAAC,CAAA,EACA,GAAAD,MAAAA,EAAAuB,OAAA,GACA,YACA,CAEA,IAAAjB,EAAAN,EAAAY,IAAA,UACA,EAIAN,KAAAA,GACAN,KAAAA,EAAAO,IAAA,IACAP,EAAAY,IAAA,GACAX,EAAAE,QAAA,CAAAC,EACA,SAIAJ,EAAAc,QAAA,YACA5B,EAAAoC,oBAAA,CAAAtB,EAAAuB,OAAA,qBAZAtB,EAAAE,QAAA,CAAAC,EACA,KACA,CAcO,IAAAsB,EAAA,CACPC,KAAA,aAEAC,WAAA,WACA,OAAYzB,SAAAC,CAAA,CACZ,EAEAyB,MAAA,SAAA7B,CAAA,CAAAC,CAAA,SACA,EAAA6B,QAAA,QACA7B,EAAAE,QAAA,CAAAH,EAAAC,EADA,CAIA","sources":["webpack://_N_E/./node_modules/@codemirror/legacy-modes/mode/tiddlywiki.js","webpack://_N_E/<anon>"],"sourcesContent":["// Tokenizer\nvar textwords = {};\n\nvar keywords = {\n  \"allTags\": true, \"closeAll\": true, \"list\": true,\n  \"newJournal\": true, \"newTiddler\": true,\n  \"permaview\": true, \"saveChanges\": true,\n  \"search\": true, \"slider\": true, \"tabs\": true,\n  \"tag\": true, \"tagging\": true, \"tags\": true,\n  \"tiddler\": true, \"timeline\": true,\n  \"today\": true, \"version\": true, \"option\": true,\n  \"with\": true, \"filter\": true\n};\n\nvar isSpaceName = /[\\w_\\-]/i,\n    reHR = /^\\-\\-\\-\\-+$/,                                 // <hr>\n    reWikiCommentStart = /^\\/\\*\\*\\*$/,            // /***\n    reWikiCommentStop = /^\\*\\*\\*\\/$/,             // ***/\n    reBlockQuote = /^<<<$/,\n\n    reJsCodeStart = /^\\/\\/\\{\\{\\{$/,                       // //{{{ js block start\n    reJsCodeStop = /^\\/\\/\\}\\}\\}$/,                        // //}}} js stop\n    reXmlCodeStart = /^<!--\\{\\{\\{-->$/,           // xml block start\n    reXmlCodeStop = /^<!--\\}\\}\\}-->$/,            // xml stop\n\n    reCodeBlockStart = /^\\{\\{\\{$/,                        // {{{ TW text div block start\n    reCodeBlockStop = /^\\}\\}\\}$/,                 // }}} TW text stop\n\n    reUntilCodeStop = /.*?\\}\\}\\}/;\n\nfunction chain(stream, state, f) {\n  state.tokenize = f;\n  return f(stream, state);\n}\n\nfunction tokenBase(stream, state) {\n  var sol = stream.sol(), ch = stream.peek();\n\n  state.block = false;        // indicates the start of a code block.\n\n  // check start of  blocks\n  if (sol && /[<\\/\\*{}\\-]/.test(ch)) {\n    if (stream.match(reCodeBlockStart)) {\n      state.block = true;\n      return chain(stream, state, twTokenCode);\n    }\n    if (stream.match(reBlockQuote))\n      return 'quote';\n    if (stream.match(reWikiCommentStart) || stream.match(reWikiCommentStop))\n      return 'comment';\n    if (stream.match(reJsCodeStart) || stream.match(reJsCodeStop) || stream.match(reXmlCodeStart) || stream.match(reXmlCodeStop))\n      return 'comment';\n    if (stream.match(reHR))\n      return 'contentSeparator';\n  }\n\n  stream.next();\n  if (sol && /[\\/\\*!#;:>|]/.test(ch)) {\n    if (ch == \"!\") { // tw header\n      stream.skipToEnd();\n      return \"header\";\n    }\n    if (ch == \"*\") { // tw list\n      stream.eatWhile('*');\n      return \"comment\";\n    }\n    if (ch == \"#\") { // tw numbered list\n      stream.eatWhile('#');\n      return \"comment\";\n    }\n    if (ch == \";\") { // definition list, term\n      stream.eatWhile(';');\n      return \"comment\";\n    }\n    if (ch == \":\") { // definition list, description\n      stream.eatWhile(':');\n      return \"comment\";\n    }\n    if (ch == \">\") { // single line quote\n      stream.eatWhile(\">\");\n      return \"quote\";\n    }\n    if (ch == '|')\n      return 'header';\n  }\n\n  if (ch == '{' && stream.match('{{'))\n    return chain(stream, state, twTokenCode);\n\n  // rudimentary html:// file:// link matching. TW knows much more ...\n  if (/[hf]/i.test(ch) &&\n      /[ti]/i.test(stream.peek()) &&\n      stream.match(/\\b(ttps?|tp|ile):\\/\\/[\\-A-Z0-9+&@#\\/%?=~_|$!:,.;]*[A-Z0-9+&@#\\/%=~_|$]/i))\n    return \"link\";\n\n  // just a little string indicator, don't want to have the whole string covered\n  if (ch == '\"')\n    return 'string';\n\n  if (ch == '~')    // _no_ CamelCase indicator should be bold\n    return 'brace';\n\n  if (/[\\[\\]]/.test(ch) && stream.match(ch)) // check for [[..]]\n    return 'brace';\n\n  if (ch == \"@\") {    // check for space link. TODO fix @@...@@ highlighting\n    stream.eatWhile(isSpaceName);\n    return \"link\";\n  }\n\n  if (/\\d/.test(ch)) {        // numbers\n    stream.eatWhile(/\\d/);\n    return \"number\";\n  }\n\n  if (ch == \"/\") { // tw invisible comment\n    if (stream.eat(\"%\")) {\n      return chain(stream, state, twTokenComment);\n    } else if (stream.eat(\"/\")) { //\n      return chain(stream, state, twTokenEm);\n    }\n  }\n\n  if (ch == \"_\" && stream.eat(\"_\")) // tw underline\n    return chain(stream, state, twTokenUnderline);\n\n  // strikethrough and mdash handling\n  if (ch == \"-\" && stream.eat(\"-\")) {\n    // if strikethrough looks ugly, change CSS.\n    if (stream.peek() != ' ')\n      return chain(stream, state, twTokenStrike);\n    // mdash\n    if (stream.peek() == ' ')\n      return 'brace';\n  }\n\n  if (ch == \"'\" && stream.eat(\"'\")) // tw bold\n    return chain(stream, state, twTokenStrong);\n\n  if (ch == \"<\" && stream.eat(\"<\")) // tw macro\n    return chain(stream, state, twTokenMacro);\n\n  // core macro handling\n  stream.eatWhile(/[\\w\\$_]/);\n  return textwords.propertyIsEnumerable(stream.current()) ? \"keyword\" : null\n}\n\n// tw invisible comment\nfunction twTokenComment(stream, state) {\n  var maybeEnd = false, ch;\n  while (ch = stream.next()) {\n    if (ch == \"/\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = (ch == \"%\");\n  }\n  return \"comment\";\n}\n\n// tw strong / bold\nfunction twTokenStrong(stream, state) {\n  var maybeEnd = false,\n      ch;\n  while (ch = stream.next()) {\n    if (ch == \"'\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = (ch == \"'\");\n  }\n  return \"strong\";\n}\n\n// tw code\nfunction twTokenCode(stream, state) {\n  var sb = state.block;\n\n  if (sb && stream.current()) {\n    return \"comment\";\n  }\n\n  if (!sb && stream.match(reUntilCodeStop)) {\n    state.tokenize = tokenBase;\n    return \"comment\";\n  }\n\n  if (sb && stream.sol() && stream.match(reCodeBlockStop)) {\n    state.tokenize = tokenBase;\n    return \"comment\";\n  }\n\n  stream.next();\n  return \"comment\";\n}\n\n// tw em / italic\nfunction twTokenEm(stream, state) {\n  var maybeEnd = false,\n      ch;\n  while (ch = stream.next()) {\n    if (ch == \"/\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = (ch == \"/\");\n  }\n  return \"emphasis\";\n}\n\n// tw underlined text\nfunction twTokenUnderline(stream, state) {\n  var maybeEnd = false,\n      ch;\n  while (ch = stream.next()) {\n    if (ch == \"_\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = (ch == \"_\");\n  }\n  return \"link\";\n}\n\n// tw strike through text looks ugly\n// change CSS if needed\nfunction twTokenStrike(stream, state) {\n  var maybeEnd = false, ch;\n\n  while (ch = stream.next()) {\n    if (ch == \"-\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    maybeEnd = (ch == \"-\");\n  }\n  return \"deleted\";\n}\n\n// macro\nfunction twTokenMacro(stream, state) {\n  if (stream.current() == '<<') {\n    return 'meta';\n  }\n\n  var ch = stream.next();\n  if (!ch) {\n    state.tokenize = tokenBase;\n    return null;\n  }\n  if (ch == \">\") {\n    if (stream.peek() == '>') {\n      stream.next();\n      state.tokenize = tokenBase;\n      return \"meta\";\n    }\n  }\n\n  stream.eatWhile(/[\\w\\$_]/);\n  return keywords.propertyIsEnumerable(stream.current()) ? \"keyword\" : null\n}\n\n// Interface\nexport const tiddlyWiki = {\n  name: \"tiddlywiki\",\n\n  startState: function () {\n    return {tokenize: tokenBase};\n  },\n\n  token: function (stream, state) {\n    if (stream.eatSpace()) return null;\n    var style = state.tokenize(stream, state);\n    return style;\n  }\n};\n\n"],"names":["textwords","keywords","isSpaceName","reHR","reWikiCommentStart","reWikiCommentStop","reBlockQuote","reJsCodeStart","reJsCodeStop","reXmlCodeStart","reXmlCodeStop","reCodeBlockStart","reCodeBlockStop","reUntilCodeStop","chain","stream","state","f","tokenize","tokenBase","sol","ch","peek","block","test","match","twTokenCode","next","skipToEnd","eatWhile","eat","twTokenComment","twTokenEm","twTokenUnderline","twTokenStrike","twTokenStrong","twTokenMacro","propertyIsEnumerable","current","maybeEnd","sb","tiddlyWiki","name","startState","token","eatSpace"],"sourceRoot":""}